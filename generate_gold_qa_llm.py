import os
import json
import csv
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI

# ============================================================
# ENV
# ============================================================
load_dotenv()

MODEL = os.getenv("MODEL_ID", "qwen/qwen-2.5-72b-instruct")
client = OpenAI(
    api_key=os.getenv("OPENROUTER_API_KEY"),
    base_url="https://openrouter.ai/api/v1",
)

# ============================================================
# CONFIG
# ============================================================

INPUT_CSV  = "data/dataset_sanitized.csv"
OUTPUT_CSV = "gold_eval_qa_250_articles.csv"

COL_ARTICLE_ID = "article_id"
COL_CHUNK_ID   = "chunk_id"
COL_DISEASE    = "root_name"
COL_ROOT_TYPE  = "root_type"
COL_TEXT       = "chunk_text"

TARGET_ROOT_TYPES = {"disease", "subdisease", "Disease", "Subdisease", "diseases", "subdiseases","topic","Topic","Diseases","Subdiseases","subtopic","Subtopic"}

LAYERS = [
    "Definition",
    "Symptom",
    "Cause",
    "RiskFactor",
    "Complication",
    "Treatment",
    "Prevention",
    "Population",
    "Context",
    "Application",
    "Advice",
    "Detail",
]

TEMPERATURE = 0.0
MAX_TOKENS  = 400

# ============================================================
# SYSTEM PROMPT
# ============================================================

SYSTEM_PROMPT = (
    "B·∫°n l√† c√¥ng c·ª• t·∫°o GOLD ANSWER cho ƒë√°nh gi√° h·ªá th·ªëng h·ªèi ƒë√°p y khoa.\n"
    "CH·ªà s·ª≠ d·ª•ng th√¥ng tin trong c√°c ƒëo·∫°n ƒë∆∞·ª£c cung c·∫•p.\n"
    "KH√îNG suy ƒëo√°n, KH√îNG th√™m ki·∫øn th·ª©c ngo√†i.\n"
    "Nhi·ªám v·ª•: tr√≠ch xu·∫•t th√¥ng tin ch√≠nh x√°c theo layer ƒë∆∞·ª£c y√™u c·∫ßu."
)

# ============================================================
# SAFE CSV LOADER (ch·ªãu CSV b·∫©n)
# ============================================================

def load_csv_safe(path: str) -> pd.DataFrame:
    rows = []
    with open(path, "r", encoding="utf-8", errors="replace") as f:
        reader = csv.reader(
            f,
            delimiter=",",
            quotechar='"',
            escapechar="\\",
            strict=False,
        )

        header = next(reader)
        n_cols = len(header)

        for row in reader:
            if not row:
                continue

            if len(row) < n_cols:
                row += [""] * (n_cols - len(row))
            elif len(row) > n_cols:
                row = row[: n_cols - 1] + [",".join(row[n_cols - 1 :])]

            rows.append(row)

    return pd.DataFrame(rows, columns=header)

# ============================================================
# QUESTION TEMPLATE
# ============================================================

def build_question(disease: str, layer: str) -> str:
    return {
        "Definition": f"{disease} l√† g√¨?",
        "Symptom": f"{disease} c√≥ nh·ªØng tri·ªáu ch·ª©ng n√†o?",
        "Cause": f"Nguy√™n nh√¢n g√¢y ra {disease} l√† g√¨?",
        "RiskFactor": f"Y·∫øu t·ªë nguy c∆° c·ªßa {disease} l√† g√¨?",
        "Complication": f"{disease} c√≥ th·ªÉ g√¢y ra nh·ªØng bi·∫øn ch·ª©ng g√¨?",
        "Treatment": f"{disease} ƒë∆∞·ª£c ƒëi·ªÅu tr·ªã nh∆∞ th·∫ø n√†o?",
        "Prevention": f"L√†m th·∫ø n√†o ƒë·ªÉ ph√≤ng ng·ª´a {disease}?",
        "Population": f"{disease} th∆∞·ªùng g·∫∑p ·ªü nh·ªØng ƒë·ªëi t∆∞·ª£ng n√†o?",
        "Context": f"{disease} trong c√°c b·ªëi c·∫£nh ƒë·∫∑c bi·ªát c·∫ßn l∆∞u √Ω ƒëi·ªÅu g√¨?",
        "Application": f"{disease} ƒë∆∞·ª£c √°p d·ª•ng ho·∫∑c x·ª≠ l√Ω trong th·ª±c t·∫ø nh∆∞ th·∫ø n√†o?",
        "Advice": f"C√≥ nh·ªØng l·ªùi khuy√™n n√†o cho ng∆∞·ªùi m·∫Øc {disease}?",
        "Detail": f"C√≥ nh·ªØng th√¥ng tin quan tr·ªçng n√†o kh√°c v·ªÅ {disease}?",
    }[layer]

# ============================================================
# LLM COMPOSER (STRICT ‚Äì KH√ìA SAI LAYER)
# ============================================================

def compose_answer_llm(disease: str, layer: str, evidences: list[dict]) -> str:
    evidence_text = "\n".join(
        f"- ({e['chunk_id']}) {e['text']}" for e in evidences
    )

    prompt = f"""
B·ªÜNH: {disease}
LAYER M·ª§C TI√äU: {layer}

C√ÇU H·ªéI:
{build_question(disease, layer)}

C√ÅC ƒêO·∫†N THAM CHI·∫æU:
{evidence_text}

Y√äU C·∫¶U B·∫ÆT BU·ªòC:
- CH·ªà tr√≠ch xu·∫•t th√¥ng tin THU·ªòC layer = {layer}
- N·∫øu KH√îNG c√≥ th√¥ng tin ph√π h·ª£p layer ‚Üí tr·∫£ v·ªÅ DUY NH·∫§T: <<EMPTY>>
- TUY·ªÜT ƒê·ªêI KH√îNG gi·∫£i th√≠ch, b√¨nh lu·∫≠n, v√≠ d·ª•
- KH√îNG d√πng ng√¥n ng·ªØ kh√°c ti·∫øng Vi·ªát
- Output = 1 ƒëo·∫°n vƒÉn HO·∫∂C <<EMPTY>>
"""

    resp = client.chat.completions.create(
        model=MODEL,
        temperature=TEMPERATURE,
        max_tokens=MAX_TOKENS,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt},
        ],
    )

    answer = (resp.choices[0].message.content or "").strip()
    return "" if answer == "<<EMPTY>>" else answer

# ============================================================
# MAIN ‚Äì T·∫†O QA CHO 10 ARTICLE ƒê·∫¶U
# ============================================================

def main():
    df = load_csv_safe(INPUT_CSV)

    df[COL_ROOT_TYPE] = df[COL_ROOT_TYPE].astype(str).str.lower()

    # üî• L·∫§Y 10 ARTICLE ƒê·∫¶U TI√äN
    first_10_articles = (
        df[COL_ARTICLE_ID]
        .dropna()
        .astype(int)      # üî• √©p v·ªÅ s·ªë
        .sort_values()    # üî• sort s·ªë
        .unique()[199:260]
        .astype(str)      # üîÅ convert l·∫°i string ƒë·ªÉ filter
)


    df = df[df[COL_ARTICLE_ID].astype(str).isin(first_10_articles)]
    df = df[df[COL_ROOT_TYPE].isin(TARGET_ROOT_TYPES)]

    out = []

    for article_id, df_article in df.groupby(COL_ARTICLE_ID):
        print(f"\nüì∞ ARTICLE {article_id}")

        for disease, g in df_article.groupby(COL_DISEASE):
            evidences = [
                {
                    "chunk_id": row[COL_CHUNK_ID],
                    "text": str(row[COL_TEXT]).strip(),
                }
                for _, row in g.iterrows()
                if str(row[COL_TEXT]).strip()
            ]

            if not evidences:
                continue

            for layer in LAYERS:
                answer = compose_answer_llm(disease, layer, evidences)
                if not answer:
                    continue  # ‚ùó layer kh√¥ng c√≥ ‚Üí b·ªè

                out.append({
                    "article_id": article_id,
                    "disease_name": disease,
                    "gold_layer": layer,
                    "question": build_question(disease, layer),
                    "gold_answer": answer,
                    "gold_evidence": json.dumps(evidences, ensure_ascii=False),
                })

            print(f"  [OK] {disease}")

    pd.DataFrame(out).to_csv(
        OUTPUT_CSV,
        index=False,
        encoding="utf-8-sig"
    )

    print("\n‚úÖ DONE")
    print(f"- Saved: {OUTPUT_CSV}")
    print(f"- Total GOLD QA: {len(out)}")

if __name__ == "__main__":
    main()
