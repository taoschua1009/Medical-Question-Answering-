import os
import re
import json
import requests
import pandas as pd
from dotenv import load_dotenv

# Load .env
load_dotenv()

BASE_URL = "https://mkp-api.fptcloud.com/chat/completions"
API_KEY = os.getenv("FPT_API_KEY")
MODEL = os.getenv("FPT_MODEL")

if not API_KEY:
    raise ValueError("‚ùå Missing FPT_API_KEY in .env")
if not MODEL:
    raise ValueError("‚ùå Missing FPT_MODEL in .env")


# ========================================================
# 1. LOAD CYPHER BLOCKS
# ========================================================
def load_cypher_blocks(path):
    with open(path, "r", encoding="utf-8") as f:
        data = f.read()

    pattern = r"// ===== Article (\d+) \| Chunk (\d+).*?=====(.*?)(?=// ===== Article|\Z)"
    matches = re.findall(pattern, data, flags=re.S)

    blocks = {}
    for article_id, chunk_id, cypher_text in matches:
        key = (int(article_id), int(chunk_id))
        blocks[key] = cypher_text.strip()

    print(f"‚úî Loaded {len(blocks)} Cypher blocks")
    return blocks


# ========================================================
# 2. PROMPT BUILDER (UPDATED WITH FAIL_REASON SUPPORT)
# ========================================================
def build_prompt(article_id, chunk_id, root_name, root_type, chunk_text, cypher_text):

    return f"""
B·∫°n l√† h·ªá th·ªëng ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng Cypher cho Neo4j t·ª´ vƒÉn b·∫£n y khoa ti·∫øng Vi·ªát.

===========================
 üéØ M·ª§C TI√äU ƒê√ÅNH GI√Å
===========================
1) Ki·ªÉm tra n·ªôi dung trong CHUNK ƒë√£ ƒë∆∞·ª£c ph√¢n lo·∫°i ƒê√öNG LAYER ch∆∞a.
2) Ki·ªÉm tra Cypher BAO PH·ª¶ ƒë·∫ßy ƒë·ªß n·ªôi dung trong CHUNK (kh√¥ng thi·∫øu node).
3) Ki·ªÉm tra Cypher KH√îNG th√™m n·ªôi dung ngo√†i CHUNK (kh√¥ng hallucinate).
4) Ki·ªÉm tra quan h·ªá ƒë√∫ng: Disease ‚Äì SubDisease ‚Äì Topic ‚Äì SubTopic ‚Äì Context ‚Äì Application.
5) **B√°o c√°o fail_reasons th·∫≠t chi ti·∫øt**, kh√¥ng ƒë∆∞·ª£c ghi chung chung.

===========================
 ‚ö†Ô∏è LU·∫¨T ƒê√ÅNH GI√Å
===========================

üìå CH·ªà ƒë√°nh gi√° nh·ªØng layer xu·∫•t hi·ªán trong CHUNK.  
Kh√¥ng ph·∫°t n·∫øu m·ªôt layer kh√¥ng t·ªìn t·∫°i trong chunk.

üìå **V·ªÅ Topic & Context**
- N·∫øu root_type = "Topic":
    MAIN_NODE = node Topic
    CONTEXT_NODE = b·ªëi c·∫£nh (Thai k·ª≥ / Mang thai / B√† b·∫ßu / Sau sinh)
- Topic c√≥ th·ªÉ thu·ªôc nhi·ªÅu context ‚Üí kh√¥ng xem Context l√† hallucination n·∫øu chunk n√≥i t·ªõi.
- N·∫øu Cypher t·∫°o context KH√îNG c√≥ trong chunk ‚Üí ƒë√≥ l√† hallucination.

üìå **V·ªÅ Application (layer m·ªõi)**
- Application l√† t√¨nh hu·ªëng √°p d·ª•ng th·ª±c t·∫ø (v√≠ d·ª•: "√°p d·ª•ng cho m·∫π b·∫ßu 3 th√°ng ƒë·∫ßu").
- N·∫øu xu·∫•t hi·ªán trong CHUNK ‚Üí Cypher PH·∫¢I t·∫°o node Application.
- N·∫øu Cypher t·∫°o Application m√† CHUNK KH√îNG ƒë·ªÅ c·∫≠p ‚Üí ƒë√≥ l√† hallucination.
- Sai layer Application ‚Üí b√°o l·ªói v√†o wrong_layer_nodes.

üìå **V·ªÅ SubDisease / SubTopic**
- N·∫øu root_type = SubDisease ho·∫∑c SubTopic ‚Üí ƒë∆∞·ª£c ph√©p t·∫°o Disease/Topic cha.
- Kh√¥ng t√≠nh hallucination.

üìå **C√°c lo·∫°i l·ªói ph·∫£i b√°o trong fail_reasons[]**
- "missing_nodes"
- "missing_application_nodes"
- "wrong_layer_nodes"
- "wrong_application_layer"
- "missing_relations"
- "missing_context_relation"
- "hallucinated_nodes"
- "hallucinated_context"
- "structure_error"
- "naming_error"

===========================
 üìå INPUT 
===========================

== ARTICLE INFO ==
article_id = {article_id}
chunk_id   = {chunk_id}
root_name  = {root_name}
root_type  = {root_type}

== CHUNK ==
\"\"\"{chunk_text}\"\"\" 

== CYPHER ==
\"\"\"{cypher_text}\"\"\" 

===========================
 üìå OUTPUT FORMAT
===========================
Tr·∫£ v·ªÅ STRICT JSON (kh√¥ng markdown):

{{
  "layer_correctness_score": 0,
  "content_coverage_score": 0,
  "hallucination_score": 0,
  "structure_score": 0,
  "naming_score": 0,

  "missing_nodes": [],
  "missing_application_nodes": [],
  "wrong_layer_nodes": [],
  "wrong_application_layer": [],
  "hallucinated_nodes": [],
  "hallucinated_context": [],
  "missing_relations": [],
  "missing_context_relation": [],

  "problems": [],
  "fail_reasons": [],
  "final_verdict": "PASS"
}}
"""



# ========================================================
# 3. CLEAN OUTPUT
# ========================================================
def clean_output(text):
    t = text.strip()
    if t.startswith("```"):
        t = t.strip("`")
        t = t.replace("json", "", 1).strip()
    return t


# ========================================================
# 4. CALL API
# ========================================================
def evaluate_pair(article_id, chunk_id, root_name, root_type, chunk_text, cypher_text):

    prompt = build_prompt(article_id, chunk_id, root_name, root_type, chunk_text, cypher_text)

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}",
    }

    payload = {
        "model": MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0,
        "max_tokens": 4096,  # tƒÉng ƒë·ªÉ tr√°nh truncate JSON
    }

    response = requests.post(BASE_URL, headers=headers, json=payload)

    try:
        content = response.json()["choices"][0]["message"]["content"]
    except:
        return {"error": response.text}

    clean = clean_output(content)

    # parse JSON safely
    try:
        return json.loads(clean)
    except:
        return {"error": "JSON_PARSE_FAILED", "raw": clean}


# ========================================================
# 5. RUN ALL
# ========================================================
def run_all(csv_file, cypher_file, output_file="judge_results.csv"):

    df = pd.read_csv(csv_file)
    cypher_blocks = load_cypher_blocks(cypher_file)

    print(f"üìå Total rows: {len(df)}")

    results = []

    for idx, row in df.iterrows():
        article_id = int(row["article_id"])
        chunk_id = int(row["chunk_id"])
        key = (article_id, chunk_id)

        cypher_text = cypher_blocks.get(key, "")

        print(f"\nüîç Evaluating Article {article_id}, Chunk {chunk_id} ...")

        result = evaluate_pair(
            article_id,
            chunk_id,
            row["root_name"],
            row["root_type"],
            row["chunk_text"],
            cypher_text,
        )

        results.append({
            "article_id": article_id,
            "chunk_id": chunk_id,
            "root_name": row["root_name"],
            "root_type": row["root_type"],
            "layer_correctness_score": result.get("layer_correctness_score"),
            "content_coverage_score": result.get("content_coverage_score"),
            "hallucination_score": result.get("hallucination_score"),
            "structure_score": result.get("structure_score"),
            "naming_score": result.get("naming_score"),
            "missing_nodes": result.get("missing_nodes"),
            "wrong_layer_nodes": result.get("wrong_layer_nodes"),
            "hallucinated_nodes": result.get("hallucinated_nodes"),
            "problems": result.get("problems"),
            "fail_reasons": result.get("fail_reasons"),
            "final_verdict": result.get("final_verdict"),
            "raw": result.get("raw"),
        })

    pd.DataFrame(results).to_csv(output_file, index=False, encoding="utf-8-sig")

    print(f"\nüéâ DONE! Saved results to {output_file}")


# ========================================================
# 6. MAIN
# ========================================================
if __name__ == "__main__":
    run_all(
        csv_file="./data_kg/csv/normalized_topic_2node.csv",
        cypher_file="./data_kg/cypher/topic_2node.cypher",
        output_file="./data_kg/judge/topic_2node_judge.csv",
    )
